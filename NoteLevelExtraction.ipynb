{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json, spacy\n",
    "import IRAEUtils\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT_DEPLOYMENT = \"OAI05-GPT35Turbo16-0613_061823\"\n",
    "#GPT_DEPLOYMENT = \"V04-GPT4Turbo-2024-04-09\"\n",
    "GPT_DEPLOYMENT = \"V05-GPT4o\"\n",
    "\n",
    "project_path = os.getenv(\"VU_PROJ_PATH\") + \"immunotoxicity/\"\n",
    "notes_path = project_path + \"in/data4llm/\"\n",
    "\n",
    "# columns: FileName (with note content), all irAE tyes in the datasets\n",
    "# rows: irAE annotations for each note\n",
    "annotations_path = project_path  +\"in/data4llm/Map.File-irAELabels.csv\"\n",
    "\n",
    "# synsets associated with each irAE type\n",
    "irae_synsets_path = project_path + \"/map_irae_prompt_detail.csv\"\n",
    "path_eval = f\"{project_path}out/llm/eval-note-level/{GPT_DEPLOYMENT}/\"\n",
    "\n",
    "filter_list_irae_full = ['Neuropathy', 'Hypothyroid', 'Myasthenia gravis (MG)', 'Rash', 'Colitis', 'Adrenal insufficiency', 'Hepatitis', 'Arthralgia', 'Duodenitis', 'Pancreatitis', 'Hypophysitis', 'Mucositis', 'Arthritis', 'Pneumonitis', 'Joint pain', 'Fever', 'Myalgia'] \n",
    "list_fname_irae_full = ['FileName'] + filter_list_irae_full\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI05_API_KEY\"),  \n",
    "  api_version =  \"2024-07-01-preview\",\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI05_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# used for light processing of LLM outputs\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load resources: maps & manual annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## maps: IRAE labes: full | norm -> large categories\n",
    "##\n",
    "dict_map_full2norm = IRAEUtils.read2cols_2dict(f\"{project_path}in/data4llm/IRAE.labels.reverse.csv\", 1, 2, \",\", True)\n",
    "dict_map_norm2large = IRAEUtils.read2cols_2dict(f\"{project_path}out/llm/eval-patient-level/map-specific2generic/IRAE.map.refined-large.03.edits.csv\", 0, 1, \",\", True)\n",
    "dict_map_full2large = dict()\n",
    "for key, value in dict_map_full2norm.items():\n",
    "    if key == 'None':\n",
    "        continue  # Skip this key-value pair\n",
    "    dict_map_full2large[key] = dict_map_norm2large[dict_map_full2norm[key]]\n",
    "\n",
    "list_coll_irae_large = IRAEUtils.read1col_2list_skip1(f\"{project_path}out/llm/eval-patient-level/map-specific2generic/IRAE.map.refined-large.03.edits.csv\", 1, \",\")\n",
    "set_irae_large = set(list_coll_irae_large)\n",
    "sorted_list_irae_large = sorted(set_irae_large)\n",
    "\n",
    "# [2] load df[notes & irAE annotations]\n",
    "#\n",
    "notelist = []\n",
    "with open(annotations_path, 'r') as f:    \n",
    "    next(f) # Skip the first line\n",
    "    for line in f:    \n",
    "        cols = line.split(',')\n",
    "        #print(os.path.join(notes_path, cols[0]))\n",
    "        with open(os.path.join(notes_path, cols[0]), 'r') as datafile:\n",
    "            notelist.append({\"FileName\":cols[0], \"text\":datafile.read()})       \n",
    "df_notes = pd.DataFrame(notelist) \n",
    "df_labels = pd.read_csv(annotations_path)\n",
    "\n",
    "df_gold_full = pd.merge(df_labels, df_notes, on='FileName')\n",
    "df10 = df_gold_full.head(10)\n",
    "\n",
    "#display(df_gold_full)\n",
    "#display(df_gold_full[list_fname_irae_full])\n",
    "#display(df_gold_full[filter_list_irae_full])\n",
    "#print(df_gold_full[filter_list_irae_full].sum(axis=0))\n",
    "#print(df10[filter_list_irae_full].sum(axis=0))\n",
    "print(f\"Number of notes: {len(df_gold_full)}\")\n",
    "\n",
    "# [3] load irAE sysnset map\n",
    "#\n",
    "list_irae_synsets =  IRAEUtils.read2cols_2list_all(irae_synsets_path, 0, 1, \"|\")\n",
    "\n",
    "dict_irae_synsets = dict()\n",
    "for tuple2 in list_irae_synsets : \n",
    "    dict_irae_synsets[tuple2[0]] = tuple2[1]\n",
    "#print(dict_irae_synsets)\n",
    "\n",
    "# [4] build the list of binary questions in json format that will be included into the prompt\n",
    "#\n",
    "ici_list = \"atezolizumab (tecentriq, atezo), avelumab (bavencio), durvalumab (imfinzi), ipilimumab (yervoy), nivolumab (opdivo, nivo), pembrolizumab (keytruda, pembro)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## irAE counts - note level\n",
    "list_all_irae_full = [irae_label for irae_label in df_gold_full.columns if irae_label not in ['FileName', 'text', 'GRID']]\n",
    "#df_gold_full['GRID'] = df_gold_full['FileName'].apply(lambda x: x.split('.')[3])\n",
    "\n",
    "df_gold_full[list_all_irae_full].sum().to_csv(project_path + \"/out/llm/notes/batches/IRAE.counts.note-level.cohort-note-subset.csv\")\n",
    "\n",
    "display(df_gold_full[list_all_irae_full].sum())\n",
    "\n",
    "filter2_list_irae_full  = []\n",
    "for irae_full in list_all_irae_full:\n",
    "        column_sum = df_gold_full[irae_full].sum()\n",
    "        if column_sum > 0 :\n",
    "                filter2_list_irae_full.append(irae_full)\n",
    "\n",
    "\n",
    "print(f'Total irAE annotated notes: {len(df_gold_full)}')\n",
    "print(list_all_irae_full)\n",
    "print(sorted(filter2_list_irae_full))\n",
    "print(sorted(filter_list_irae_full))\n",
    "\n",
    "#display(df_gold_full[['GRID'] + list_fname_irae_full])\n",
    "#display([list_fname_irae_full])\n",
    "#display(df_gold_full[list_fname_irae_full])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert full to large irAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## init row dictionaries for converting specific to large irAE categs\n",
    "## \n",
    "def init_dict_large_irae(list_irae_large) : \n",
    "    dict_large_irae = dict()\n",
    "    for irae_large in list_irae_large :\n",
    "        dict_large_irae[irae_large] = 0\n",
    "\n",
    "    return dict_large_irae\n",
    "\n",
    "## convert specific to large irAE patient dataframe\n",
    "## \n",
    "def convert_specific_large(df_irae_full, dict_map_full2large, list_irae_full, list_irae_large) :\n",
    "    df_irae_large = pd.DataFrame(columns = list_irae_large)    \n",
    "\n",
    "    for index, row in df_irae_full.iterrows():\n",
    "        dict_row = init_dict_large_irae(list_irae_large)\n",
    "        for irae_full in list_irae_full :\n",
    "            if row[irae_full] == 1 :\n",
    "                dict_row[dict_map_full2large[irae_full]] = 1\n",
    "                \n",
    "        df_irae_large = pd.concat([df_irae_large, pd.DataFrame([dict_row])], ignore_index=True)\n",
    "    \n",
    "    return df_irae_large\n",
    "\n",
    "## convert gold full irAE to gold large irAE\n",
    "##\n",
    "df_gold_large = convert_specific_large(df_gold_full[filter_list_irae_full], dict_map_full2large, filter_list_irae_full, sorted_list_irae_large)\n",
    "display(df_gold_large)\n",
    "\n",
    "## Build irAE large filter list (exclude null irAEs large labels)\n",
    "##\n",
    "filter_list_irae_large  = []\n",
    "for irae_large in sorted_list_irae_large:\n",
    "        column_sum = df_gold_large[irae_large].sum()\n",
    "        if column_sum > 0 :\n",
    "                filter_list_irae_large.append(irae_large)\n",
    "\n",
    "print(f\"sorted_list_irae_large:{len(sorted_list_irae_large)} -- filter_list_irae_large:{len(filter_list_irae_large)}\")\n",
    "print(set(sorted_list_irae_large) - set(filter_list_irae_large))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRAE zero-shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_irae_list_json(irae_list):\n",
    "    s = '{'\n",
    "    for irae_label in irae_list :\n",
    "        s += f'''\\n\"{irae_label}\": Output 'Yes' if the patient has experienced {dict_irae_synsets[irae_label]} because of exposure to one or more immune checkpoint inhibitors. Otherwise, output 'No'.,'''\n",
    "    s += '}'\n",
    "\n",
    "    return s\n",
    "\n",
    "print(get_irae_list_json(filter_list_irae_full))\n",
    "\n",
    "def prompt_specific_json(note_text, ici_list, irae_list):\n",
    "    irae_json_format = get_irae_list_json(irae_list)\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": f\"\"\"You are a clinical expert in identifying immune-related adverse events (irAEs) caused by immune checkpoint inhibitors (ICIs).                                           \n",
    "                     You will receive as input a patient note corresponding to a patient who was treated or is currently treated with one or multiple immune checkpoint inhibitors (ICIs) from the following ICI list: {ici_list}. \n",
    "                     Your task is to determine if the patient note describes any of the immune-related adverse events (irAEs) experienced by the patient and caused by immune checkpoint inhibitors.\n",
    "                     Output your response in a JSON format using the following structure: \n",
    "                     {irae_json_format}\"\"\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"\"\"Does the following patient note describe immune-related adverse \n",
    "                     events experienced by the patient? \n",
    "                     Patient note: {note_text}\"\"\"})                     \n",
    "    return messages\n",
    "\n",
    "#print(prompt_specific_json(\" .. test .. \", ici_list, filter_list_irae_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM output processisng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returns <Flag , list01> True if successfully parsed\n",
    "##\n",
    "def convert_yn_dict_to_01_list(dict_irae_reponse, irae_list, nlp) :\n",
    "    response_01_list = []\n",
    "    for irae_elem in irae_list :\n",
    "        response_01_elem = IRAEUtils.convert_llm_response_to_01(dict_irae_reponse[irae_elem], nlp)\n",
    "        #print(f\"{irae_elem} : {dict_irae_reponse[irae_elem]} : {response_01_elem}\")\n",
    "        response_01_list.append(response_01_elem)\n",
    "        if response_01_elem == -1 :\n",
    "            return False, response_01_list\n",
    "    \n",
    "    return True, response_01_list\n",
    "\n",
    "##\n",
    "##\n",
    "def filter_invalid_llm_responses(y_gold, y_llm_yn, irae_list, nlp) :\n",
    "    #print(f\"before: filter_invalid_llm_responses: {len(y_gold)} <> {len(y_llm_yn)}\")\n",
    "    \n",
    "    y_gold_filter = np.empty((0, len(irae_list)))\n",
    "    y_llm_filter = np.empty((0, len(irae_list)))\n",
    "\n",
    "    for row_y_gold, llm_response_yn in zip(y_gold, y_llm_yn) :\n",
    "        #print(f\"\\nrow_y_gold({row_y_gold})\")\n",
    "        #print(f\"llm_response_yn({llm_response_yn})\")\n",
    "        json_llm_response_yn = llm_response_yn.removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
    "        if IRAEUtils.is_json(json_llm_response_yn) :\n",
    "            dict_irae_reponse = json.loads(json_llm_response_yn)\n",
    "            flag, llm_response_01 = convert_yn_dict_to_01_list(dict_irae_reponse, irae_list, nlp)\n",
    "\n",
    "            if flag == True :\n",
    "                #print(f\"llm_response_01({llm_response_01})\")\n",
    "                y_gold_filter = np.vstack([y_gold_filter, row_y_gold])\n",
    "                y_llm_filter = np.vstack([y_llm_filter, llm_response_01])\n",
    "\n",
    "                #print(f\"\\ny_gold_filter({y_gold_filter})\")\n",
    "                #print(f\"y_llm_filter({y_llm_filter})\")\n",
    "\n",
    "    #print(f\"after: filter_invalid_llm_responses: {len(y_gold_filter)} <> {len(y_llm_filter)}\")\n",
    "    return y_gold_filter, y_llm_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_all = df10[[\"text\"]].values\n",
    "#y_all = df10[filter_list_irae_full].values\n",
    "\n",
    "X_all = df_gold_full[[\"text\"]].values\n",
    "y_all = df_gold_full[filter_list_irae_full].values\n",
    "\n",
    "exception_list = []\n",
    "y_llmresponses = []\n",
    "#for note in X_all:\n",
    "for index, note in enumerate(X_all):\n",
    "    try:\n",
    "        llm_response = llm.chat.completions.create(model = GPT_DEPLOYMENT,\n",
    "            temperature=0.0, max_tokens=500, n = 1,\n",
    "            frequency_penalty=0, presence_penalty=0, seed = 13,     \n",
    "            #top_p=1, ## reco: alter this param or temp but not both https://platform.openai.com/docs/api-reference/chat/create            \n",
    "            #messages = prompt_func(note))\n",
    "            messages = prompt_specific_json(note, ici_list, filter_list_irae_full))                                \n",
    "        \n",
    "        print(\"Note: \"+str(index))\n",
    "        #print(\"Prompt: \"+str(prompt_func(note, ici_list, irae_list)))\n",
    "        print(llm_response.choices[0].message.content.strip())\n",
    "        y_llmresponses.append(llm_response.choices[0].message.content.strip())\n",
    "        #print(response)\n",
    "        #print('.', end='', flush=True)\n",
    "    except Exception as e:            \n",
    "        print(\"LLMException: \"+str(e).strip().replace('\\n', ' '))\n",
    "        y_llmresponses.append(\"LLMException: \"+str(e).strip().replace('\\n', ' '))\n",
    "        exception_list.append(\"LLMException: \"+str(e).strip().replace('\\n', ' '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation [full]: filtered irAE full labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_filter, y_llmresponses_filter = filter_invalid_llm_responses(y_all, y_llmresponses, filter_list_irae_full, nlp)\n",
    "\n",
    "clf_report = classification_report(y_all_filter, y_llmresponses_filter, target_names = filter_list_irae_full, zero_division=0, output_dict=True)\n",
    "df_clf_report = pd.DataFrame(clf_report).transpose()\n",
    "display(df_clf_report)\n",
    "\n",
    "df_irae_full_eval = IRAEUtils.irae_eval(y_all_filter, y_llmresponses_filter, filter_list_irae_full)\n",
    "display(df_irae_full_eval)\n",
    "\n",
    "df_clf_report.to_csv(f\"{path_eval}EVAL-FULL.CLF-REPORT.{GPT_DEPLOYMENT}.csv\", index=True)\n",
    "df_irae_full_eval.to_csv(f\"{path_eval}EVAL-FULL.DETAILED-REPORT.{GPT_DEPLOYMENT}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation [large]: filtered irAE large labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert np.array with binary labels for irAE full to df with binary labels for irAE large\n",
    "##\n",
    "def convert_np_full_to_df_large(np_irae_full, dict_map_full2large, list_irae_full, list_irae_large) :\n",
    "    df_irae_large = pd.DataFrame(columns = list_irae_large)\n",
    "     \n",
    "    for row in np_irae_full :\n",
    "        dict_row = init_dict_large_irae(list_irae_large)\n",
    "        for index_irae_full, label_irae_full in enumerate(list_irae_full):\n",
    "            if row[index_irae_full] == 1 :\n",
    "                    dict_row[dict_map_full2large[label_irae_full]] = 1\n",
    "\n",
    "        df_irae_large = pd.concat([df_irae_large, pd.DataFrame([dict_row])], ignore_index=True)\n",
    "    \n",
    "    return df_irae_large\n",
    "\n",
    "\n",
    "df_y_all_filter = convert_np_full_to_df_large(y_all_filter, dict_map_full2large, filter_list_irae_full, filter_list_irae_large)\n",
    "df_y_llmresponses_filter = convert_np_full_to_df_large(y_llmresponses_filter, dict_map_full2large, filter_list_irae_full, filter_list_irae_large)\n",
    "\n",
    "np_y_all_filter = df_y_all_filter.to_numpy().astype(int)\n",
    "np_y_llmresponses_filter = df_y_llmresponses_filter.to_numpy().astype(int)\n",
    "\n",
    "final_clf_report = classification_report(np_y_all_filter, np_y_llmresponses_filter, target_names = filter_list_irae_large, zero_division=0, output_dict=True)\n",
    "final_clf_report = pd.DataFrame(final_clf_report).transpose()\n",
    "display(final_clf_report)\n",
    "\n",
    "final_df_irae_large_eval = IRAEUtils.irae_eval(np_y_all_filter, np_y_llmresponses_filter, filter_list_irae_large)\n",
    "display(final_df_irae_large_eval)\n",
    "\n",
    "final_clf_report.to_csv(f\"{path_eval}EVAL-LARGE.CLF-REPORT.{GPT_DEPLOYMENT}.csv\", index=True)\n",
    "final_df_irae_large_eval.to_csv(f\"{path_eval}EVAL-LARGE.DETAILED-REPORT.{GPT_DEPLOYMENT}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
